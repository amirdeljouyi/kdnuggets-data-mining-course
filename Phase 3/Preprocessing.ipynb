{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'ALL_AML_grow.train.orig.txt'\n",
    "test_file = 'ALL_AML_grow.test.orig.txt'\n",
    "sample_file = 'table_ALL_AML_samples.txt'\n",
    "train_idclass_file = 'ALL_AML_idclass.train.txt'\n",
    "test_idclass_file = 'ALL_AML_idclass.test.txt'\n",
    "train_tmp_file = 'LL_AML_grow.train.noaffy.tmp'\n",
    "test_tmp_file = 'ALL_AML_grow.test.noaffy.tmp'\n",
    "norm_train_file = 'ALL_AML_grow.train.norm.tmp'\n",
    "norm_test_file = 'ALL_AML_grow.test.norm.tmp'\n",
    "gcol_train_file = 'ALL_AML_gcol.train.tmp'\n",
    "gcol_test_file = 'ALL_AML_gcol.test.tmp'\n",
    "gcol_class_test_file = 'ALL_AML_gcol_class.test.csv'\n",
    "gcol_class_train_file = 'ALL_AML_gcol_class.train.csv'\n",
    "removable_word = 'endogenous control'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microarray Data Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Control from Gene Description and Replacing Commas with semicolon :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of endogenous control in ALL_AML_grow.train.orig.txt : 58\n",
      "Number of occurrences of endogenous control in ALL_AML_grow.test.orig.txt : 58\n"
     ]
    }
   ],
   "source": [
    "def remove_rows(file_path,tmp_path,removable):\n",
    "    data = pd.read_csv(file_path, sep='\\t',index_col=False)\n",
    "    selected_rows = [g.find(removable) == -1 for g in data['Gene Description']]\n",
    "    print('Number of occurrences of {} in {} : {}'.format(removable,file_path,np.sum(np.array(selected_rows) == False)))\n",
    "    data = data[selected_rows]\n",
    "    data.to_csv(tmp_path,index=False)\n",
    "remove_rows(train_file,train_tmp_file,removable_word)\n",
    "remove_rows(test_file,test_tmp_file,removable_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary columns and renaming \"Gene Accession Number\" column to \"ID\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unnecessary_columns(file_path) :\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data[np.append(data.columns[1],data.columns[2::2])]\n",
    "    data.columns = np.append(['ID'],data.columns[1:])\n",
    "    return data\n",
    "train_data = remove_unnecessary_columns(train_tmp_file)\n",
    "test_data = remove_unnecessary_columns(test_tmp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limiting Attributes Value, between 20 and 16000 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data,save_path) :\n",
    "    data = data.applymap(lambda x:x if type(x) == str or (x > 20 and x < 16000) else None)\n",
    "    data.to_csv(save_path,index=False)\n",
    "normalize_data(train_data,norm_train_file)\n",
    "normalize_data(test_data,norm_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing Matrix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ALL_AML_grow.train.norm.tmp : (39, 7071)\n",
      "Shape of ALL_AML_grow.test.norm.tmp : (35, 7071)\n"
     ]
    }
   ],
   "source": [
    "def tansposing_matrix(data_path,save_path) :\n",
    "    data = pd.read_csv(data_path).transpose()\n",
    "    print('Shape of {} : {}'.format(data_path,data.shape))\n",
    "    data.to_csv(save_path)\n",
    "tansposing_matrix(norm_train_file,gcol_train_file)\n",
    "tansposing_matrix(norm_test_file,gcol_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging ClassId tables With Gcol tables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(pd.read_csv(gcol_test_file,header=1),\n",
    "                   pd.read_csv(test_idclass_file),on=\"ID\") \\\n",
    "                        .to_csv(gcol_class_test_file,index=False)\n",
    "    \n",
    "pd.merge(pd.read_csv(gcol_train_file,header=1),\n",
    "                   pd.read_csv(train_idclass_file),on=\"ID\") \\\n",
    "                        .to_csv(gcol_class_train_file,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
